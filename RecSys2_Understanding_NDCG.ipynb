{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/IMvunY3LrQI"
      ],
      "metadata": {
        "id": "czWi8YY51Gex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding NDCG (Normalized Discounted Cumulative Gain)\n",
        "## The Right Way to Evaluate Recommendation System Performance"
      ],
      "metadata": {
        "id": "I6MS0O8AULuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is NDCG?\n",
        "\n",
        "NDCG measures **how well your recommendation system ranks relevant items**. It's the gold standard metric for evaluating ranking quality in search engines, recommendation systems, and information retrieval.\n",
        "\n",
        "**Key Idea:** Relevant items should appear at the top of your recommendations. Items ranked higher contribute more to your score.\n",
        "\n",
        "---\n",
        "\n",
        "## How NDCG is Calculated (Simple Explanation)\n",
        "\n",
        "### Step 1: Calculate DCG (Discounted Cumulative Gain)\n",
        "\n",
        "DCG measures the usefulness of recommendations based on their position:\n",
        "\n",
        "$$\\text{DCG@K} = \\sum_{i=1}^{K} \\frac{\\text{rel}_i}{\\log_2(i + 1)}$$\n",
        "\n",
        "Where:\n",
        "- $\\text{rel}_i$ = relevance of item at position i (1 if relevant, 0 if not)\n",
        "- $\\log_2(i + 1)$ = position discount (items lower in the list count less)\n",
        "- K = how many top items to evaluate (e.g., top 5)\n",
        "\n",
        "**Example:** User bought [milk, eggs, bread]  \n",
        "Your model ranks: [eggs, cheese, milk, bread, ...]\n",
        "\n",
        "$$\\text{DCG@3} = \\frac{1}{\\log_2(2)} + \\frac{0}{\\log_2(3)} + \\frac{1}{\\log_2(4)} = \\frac{1}{1.0} + \\frac{0}{1.585} + \\frac{1}{2.0} = 1.0 + 0.0 + 0.5 = 1.5$$\n",
        "\n",
        "### Step 2: Calculate IDCG (Ideal DCG)\n",
        "\n",
        "IDCG is the **best possible DCG** if all relevant items were perfectly ranked:\n",
        "\n",
        "Perfect ranking: [milk, eggs, bread, ...]\n",
        "\n",
        "$$\\text{IDCG@3} = \\frac{1}{\\log_2(2)} + \\frac{1}{\\log_2(3)} + \\frac{1}{\\log_2(4)} = 1.0 + 0.631 + 0.5 = 2.131$$\n",
        "\n",
        "### Step 3: Calculate NDCG (Normalize)\n",
        "\n",
        "$$\\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}}$$\n",
        "\n",
        "In our example:\n",
        "\n",
        "$$\\text{NDCG@3} = \\frac{1.5}{2.131} = 0.704 \\text{ (70.4% of perfect)}$$\n",
        "\n",
        "**Interpretation:** Your model achieved 70% of the perfect ranking score.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Logarithmic Discounting?\n",
        "\n",
        "Position matters, but with **diminishing returns**:\n",
        "\n",
        "| Position | Weight | Discount | Importance |\n",
        "|----------|--------|----------|------------|\n",
        "| 1 | 1.000 | 0% | ⭐⭐⭐ Most important! |\n",
        "| 2 | 0.631 | 37% | ⭐⭐⭐ Very important |\n",
        "| 3 | 0.500 | 50% | ⭐⭐ Important |\n",
        "| 5 | 0.387 | 61% | ⭐ Moderate |\n",
        "| 10 | 0.301 | 70% | Less important |\n",
        "\n",
        "**Why?** Users heavily favor top results. The difference between #1 and #2 is huge, but between #8 and #9 is small.\n",
        "\n",
        "---\n",
        "\n",
        "## NDCG Properties\n",
        "\n",
        "**Range:** 0 to 1 (1 = perfect ranking)  \n",
        "**Position-aware:** Order matters!  \n",
        "**Normalized:** Comparable across different queries/users  \n",
        "**Works with graded relevance:** Can use 0/1/2/3 instead of just 0/1  \n",
        "\n",
        "---\n",
        "\n",
        "## NDCG@K Interpretation\n",
        "\n",
        "- **NDCG@1:** How good is your #1 recommendation?\n",
        "- **NDCG@3:** Quality of your top 3 (critical for mobile)\n",
        "- **NDCG@5:** Quality of your top 5 (first screen)\n",
        "- **NDCG@10:** Overall top 10 quality\n",
        "\n",
        "**Rule:** Always check multiple K values! A model that gets NDCG@1 = 0.80 but NDCG@5 = 0.30 is inconsistent.\n",
        "\n",
        "---\n",
        "\n",
        "## Realistic NDCG Expectations\n",
        "\n",
        "**With sparse e-commerce data (5-10% purchase rate):**\n",
        "\n",
        "| Model Type | NDCG@5 | vs Random | Status |\n",
        "|------------|--------|-----------|--------|\n",
        "| Random Baseline | 0.05-0.10 | 1x | Baseline |\n",
        "| Good Model | 0.40-0.60 | 5-8x | Deploy! |\n",
        "| Excellent Model | 0.70-0.85 | 10-15x | Top tier! |\n",
        "\n",
        "**Why so \"low\"?**\n",
        "- When users buy 3 items from 50 products (6% rate)\n",
        "- Random gets ~0.06 NDCG\n",
        "- Your 0.50 NDCG = 8x improvement = **EXCELLENT!**\n",
        "- This translates to 20-30% revenue increase\n",
        "\n",
        "**Don't chase 0.90+** - That requires 40-50% relevance (unrealistic for e-commerce)\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **Position is everything:** Same items, wrong order = low NDCG\n",
        "2. **Compare to random baseline:** Your improvement ratio matters most\n",
        "3. **Check multiple K values:** Consistency is important\n",
        "4. **NDCG 0.50 can be excellent:** Depends on your data sparsity\n",
        "\n",
        "Now, let's see this in action!"
      ],
      "metadata": {
        "id": "6ev9YaCqGiWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "Setting up our environment for NDCG calculations.\n",
        "\n"
      ],
      "metadata": {
        "id": "OFsKMwTzVjBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# For reproducibility\n",
        "rng = np.random.default_rng(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "BPKdKG7PVo5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulated, yet realistic Product Catalog\n",
        "\n",
        "**50 products** across 8 categories - realistic online grocery store:\n",
        "- Dairy (8 items)\n",
        "- Bakery (6 items)  \n",
        "- Produce (10 items)\n",
        "- Meat & Protein (6 items)\n",
        "- Pantry (10 items)\n",
        "- Beverages (5 items)\n",
        "- Snacks (3 items)\n",
        "- Frozen (2 items)\n"
      ],
      "metadata": {
        "id": "iaDYsjpXVqcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products = [\n",
        "    # Dairy (8 items)\n",
        "    \"milk\", \"eggs\", \"butter\", \"yogurt\", \"cheese\", \"cream\", \"sour_cream\", \"cottage_cheese\",\n",
        "    # Bakery (6 items)\n",
        "    \"bread\", \"bagels\", \"muffins\", \"croissants\", \"tortillas\", \"pita_bread\",\n",
        "    # Produce (10 items)\n",
        "    \"bananas\", \"apples\", \"oranges\", \"lettuce\", \"tomatoes\", \"onions\",\n",
        "    \"carrots\", \"potatoes\", \"peppers\", \"cucumbers\",\n",
        "    # Meat & Protein (6 items)\n",
        "    \"chicken\", \"beef\", \"pork\", \"salmon\", \"tuna\", \"turkey\",\n",
        "    # Pantry (10 items)\n",
        "    \"pasta\", \"rice\", \"beans\", \"flour\", \"sugar\", \"salt\",\n",
        "    \"olive_oil\", \"cereal\", \"oatmeal\", \"coffee\",\n",
        "    # Beverages (5 items)\n",
        "    \"orange_juice\", \"apple_juice\", \"soda\", \"tea\", \"water_bottles\",\n",
        "    # Snacks (3 items)\n",
        "    \"chips\", \"crackers\", \"cookies\",\n",
        "    # Frozen (2 items)\n",
        "    \"ice_cream\", \"frozen_pizza\"\n",
        "]\n",
        "\n",
        "print(f\"Product catalog: {len(products)} items\")\n",
        "print(f\"Categories: Dairy, Bakery, Produce, Meat, Pantry, Beverages, Snacks, Frozen\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Pth7_UVveg",
        "outputId": "9622c131-17f5-4732-d051-073b5b2daa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product catalog: 50 items\n",
            "Categories: Dairy, Bakery, Produce, Meat, Pantry, Beverages, Snacks, Frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realistic Purchase Patterns\n",
        "\n",
        "**10 users**, each buying 2-4 items from 50 products (4-8% purchase rate).\n",
        "\n",
        "**This sparsity is REALISTIC:**\n",
        "- Most people don't buy 50 items per shopping trip\n",
        "- Average basket: 2-4 items for quick shopping  \n",
        "- Makes NDCG more challenging but mirrors reality\n",
        "\n",
        "**Hand-crafted patterns:**\n",
        "- User 1: Dairy + Produce (breakfast shopper)\n",
        "- User 2: Bread + Meat + Pasta (dinner prep)\n",
        "- User 3: Dairy + Beverages (coffee run)\n",
        "- User 4: Produce + Fish (health conscious)\n",
        "- And so on...\n"
      ],
      "metadata": {
        "id": "cJjbs5FeVxsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hand-craft realistic purchase patterns\n",
        "# Users tend to buy from 2-3 categories per trip\n",
        "true_purchases = np.array([\n",
        "    # User 1: Dairy + Produce basics (4 items)\n",
        "    [1, 1, 0, 0, 0, 0, 0, 0,  # Dairy: milk, eggs\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     1, 1, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: bananas, apples\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: none\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 2: Bakery + Meat + Pantry (3 items)\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0,  # Dairy: none\n",
        "     1, 0, 0, 0, 0, 0,        # Bakery: bread\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     1, 0, 0, 0, 0, 0,        # Meat: chicken\n",
        "     1, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: pasta\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 3: Dairy + Beverages + Snacks (4 items)\n",
        "    [1, 0, 0, 1, 0, 0, 0, 0,  # Dairy: milk, yogurt\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 1,  # Pantry: coffee\n",
        "     1, 0, 0, 0, 0,           # Beverages: OJ\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 4: Produce heavy + Meat (4 items)\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0,  # Dairy: none\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 0, 0, 1, 1, 1, 0, 0, 0, 0,  # Produce: lettuce, tomatoes, onions\n",
        "     0, 0, 0, 1, 0, 0,        # Meat: salmon\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: none\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 5: Pantry staples (3 items)\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0,  # Dairy: none\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 1, 1, 0, 0, 0, 1, 0, 0, 0,  # Pantry: rice, beans, olive_oil\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 6: Dairy + Bakery (3 items)\n",
        "    [0, 1, 1, 0, 0, 0, 0, 0,  # Dairy: eggs, butter\n",
        "     1, 0, 0, 0, 0, 0,        # Bakery: bread\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: none\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 7: Quick dinner (3 items)\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0,  # Dairy: none\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 0, 0, 0, 1, 0, 0, 0, 0, 0,  # Produce: tomatoes\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     1, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: pasta\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 1],                   # Frozen: frozen_pizza\n",
        "\n",
        "    # User 8: Breakfast items (4 items)\n",
        "    [1, 1, 0, 0, 0, 0, 0, 0,  # Dairy: milk, eggs\n",
        "     0, 1, 0, 0, 0, 0,        # Bakery: bagels\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 1,  # Pantry: coffee\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 9: Snack run (2 items)\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0,  # Dairy: none\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Produce: none\n",
        "     0, 0, 0, 0, 0, 0,        # Meat: none\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: none\n",
        "     0, 0, 1, 0, 0,           # Beverages: soda\n",
        "     1, 0, 0,                 # Snacks: chips\n",
        "     0, 0],                   # Frozen: none\n",
        "\n",
        "    # User 10: Healthy basket (4 items)\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0,  # Dairy: yogurt\n",
        "     0, 0, 0, 0, 0, 0,        # Bakery: none\n",
        "     0, 1, 0, 1, 0, 0, 0, 0, 0, 0,  # Produce: apples, lettuce\n",
        "     0, 0, 0, 1, 0, 0,        # Meat: salmon\n",
        "     0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  # Pantry: none\n",
        "     0, 0, 0, 0, 0,           # Beverages: none\n",
        "     0, 0, 0,                 # Snacks: none\n",
        "     0, 0],                   # Frozen: none\n",
        "])\n",
        "\n",
        "df_true = pd.DataFrame(true_purchases, columns=products)\n",
        "df_true.index = [f\"user_{i+1}\" for i in range(len(df_true))]\n",
        "\n",
        "print(\"Ground Truth (Actual Purchases):\")\n",
        "print(df_true.sum(axis=1))\n",
        "print(f\"\\nTotal items bought per user: {df_true.sum(axis=1).values}\")\n",
        "print(f\"Average purchase rate: {df_true.mean().mean():.1%}\")\n",
        "print(f\"This sparse data (5%) is REALISTIC for e-commerce!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YydVrEMoV2jj",
        "outputId": "30fa516a-d4e8-474a-e984-aacd8bc9761e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth (Actual Purchases):\n",
            "user_1     4\n",
            "user_2     3\n",
            "user_3     4\n",
            "user_4     4\n",
            "user_5     3\n",
            "user_6     3\n",
            "user_7     3\n",
            "user_8     4\n",
            "user_9     2\n",
            "user_10    4\n",
            "dtype: int64\n",
            "\n",
            "Total items bought per user: [4 3 4 4 3 3 3 4 2 4]\n",
            "Average purchase rate: 6.8%\n",
            "This sparse data (5%) is REALISTIC for e-commerce!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scenario 1 - Perfect Ranking\n",
        "\n",
        "Perfect model = Ground truth as prediction scores.\n",
        "\n",
        "**Expected:** NDCG = 1.0000 (theoretical maximum)\n",
        "\n",
        "**Important:** You'll NEVER achieve this in production with sparse data!\n",
        "\n",
        "This is just a reference point to understand the metric.\n",
        "\n",
        "*sklearn.metrics.ndcg_score(y_true, y_score, k=None, sample_weight=None, ignore_ties=False)*\n",
        "\n",
        "y_true: array-like of shape (n_samples, n_labels)\n",
        "True targets of multilabel classification, or true scores of entities to be ranked. Negative values in y_true may result in an output that is not between 0 and 1.\n",
        "<p>\n",
        "y_score: array-like of shape (n_samples, n_labels)\n",
        "Target scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions (as returned by “decision_function” on some classifiers).\n",
        "<p>\n",
        "k: int, default=None\n",
        "Only consider the highest k scores in the ranking. If None, use all outputs."
      ],
      "metadata": {
        "id": "xYQa16oYV56S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perfect_scores = true_purchases.astype(float)\n",
        "df_perfect = pd.DataFrame(perfect_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PERFECT MODEL (Theoretical Maximum)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_perfect, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6A5w-uqV9BI",
        "outputId": "b681eb45-d6df-4c1a-cc25-1d2e4245b92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PERFECT MODEL (Theoretical Maximum)\n",
            "============================================================\n",
            "NDCG@1 = 1.0000\n",
            "NDCG@3 = 1.0000\n",
            "NDCG@5 = 1.0000\n",
            "NDCG@10 = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2 - Inverted Ranking (Systematically Wrong Model)\n",
        "\n",
        "In this scenario, the ground truth does not change, only the model’s predicted scores are inverted, causing irrelevant items to be ranked above relevant ones. So it creates the worst possible ordering, which is why NDCG collapses to ~0.\n",
        "\n",
        "Items the user will buy → assigned the lowest scores (ranked last)\n",
        "\n",
        "Items the user won’t buy → assigned the highest scores (ranked first)\n",
        "\n",
        "**As a result**\n",
        "\n",
        "All irrelevant items dominate the top of the ranking\n",
        "\n",
        "All relevant items are pushed to the bottom\n",
        "\n",
        "DCG ≈ 0 ⇒ NDCG ≈ 0.000\n",
        "\n",
        "**Key Learning**\n",
        "\n",
        "- NDCG does not merely evaluate order, it evaluates whether relevant items are ranked above irrelevant ones.\n",
        "\n",
        "- Having the right items somewhere in the list is not enough\n",
        "\n",
        "- If irrelevant items are ranked ahead of relevant ones, ranking quality collapses\n",
        "\n",
        "**A confidently wrong model is worse than a noisy or random one**"
      ],
      "metadata": {
        "id": "3nJA3q8bCSdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_scores = 1.0 - true_purchases.astype(float)\n",
        "df_inverted = pd.DataFrame(inverted_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"INVERTED MODEL (Right items, wrong order)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_inverted, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n⚠️  Same items, reversed order → Near-zero NDCG!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUSx7LWoWCxf",
        "outputId": "da840073-7c71-495d-c25f-37eab1050365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INVERTED MODEL (Right items, wrong order)\n",
            "============================================================\n",
            "NDCG@1 = 0.0000\n",
            "NDCG@3 = 0.0000\n",
            "NDCG@5 = 0.0000\n",
            "NDCG@10 = 0.0000\n",
            "\n",
            "⚠️  Same items, reversed order → Near-zero NDCG!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 3 - Excellent Production Model\n",
        "\n",
        "**Target NDCG: 0.35-0.42** (realistic top-tier performance)\n",
        "\n",
        "**Scenario summary:**\n",
        "\n",
        "This scenario represents an excellent but imperfect ranking model where relevant items are usually ranked above irrelevant ones, with occasional realistic mistakes.\n",
        "\n",
        "**How it’s simulated:** Purchased items are assigned random high scores (≈0.60-0.90) while non-purchased items receive low scores (≈0.10-0.40), creating strong score separation. To reflect real-world noise, 1-2 non-relevant items per user are randomly boosted into the high-score range, slightly degrading, but not breaking the ranking.\n",
        "\n",
        "**Why is 0.35 considered \"excellent\"?**\n",
        "- Random baseline = 0.10\n",
        "- Excellent model = 0.35\n",
        "- That's 3.5x better than random!\n",
        "- Translates to 20-30% revenue increase\n",
        "\n",
        "**This is hand-crafted** to guarantee consistent NDCG for teaching.\n",
        "In production, you'd train ML models to achieve these results."
      ],
      "metadata": {
        "id": "pa_nNt2TWGPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create strong separation between relevant and irrelevant\n",
        "excellent_scores = np.where(\n",
        "    true_purchases == 1,\n",
        "    rng.uniform(0.60, 0.90, true_purchases.shape),  # Relevant: high scores\n",
        "    rng.uniform(0.50, 0.70, true_purchases.shape)   # Irrelevant: low scores\n",
        ")\n",
        "\n",
        "# Create some realistic errors (1-2 per user)\n",
        "for i in range(len(excellent_scores)):\n",
        "    wrong_indices = np.where(true_purchases[i] == 0)[0]\n",
        "    # Boost 1-2 wrong items\n",
        "    boost_count = min(2, len(wrong_indices))\n",
        "    boost_items = rng.choice(wrong_indices, size=boost_count, replace=False)\n",
        "    for idx in boost_items:\n",
        "        excellent_scores[i, idx] = rng.uniform(0.65, 0.85)\n",
        "\n",
        "df_excellent = pd.DataFrame(excellent_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EXCELLENT MODEL (Top-Tier Production)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_excellent, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n✅ NDCG@5 ~0.50-0.70 is EXCELLENT for sparse e-commerce data!\")\n",
        "print(f\"   Separation gap: ~0.35 (strong signal)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShKZQaxYWKKv",
        "outputId": "cac74328-f19c-41f0-8eae-26a131397636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXCELLENT MODEL (Top-Tier Production)\n",
            "============================================================\n",
            "NDCG@1 = 0.6000\n",
            "NDCG@3 = 0.5675\n",
            "NDCG@5 = 0.6595\n",
            "NDCG@10 = 0.6725\n",
            "\n",
            "✅ NDCG@5 ~0.50-0.70 is EXCELLENT for sparse e-commerce data!\n",
            "   Separation gap: ~0.35 (strong signal)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 4 - Good Production Model\n",
        "\n",
        "**Target NDCG: 0.25-0.35** (solid, deployable)\n",
        "\n",
        "**Strategy:**\n",
        "- More ranking errors than \"Excellent\"\n",
        "- 2-3 wrong items in top 5 per user\n",
        "- Some relevant items ranked in positions 6-10\n",
        "\n",
        "**Why is 0.28 \"good\"?**\n",
        "- It's 2.8x better than random\n",
        "- Deploy with confidence!\n",
        "- Most real-world systems operate here\n",
        "\n",
        "**Real-world note:** If you achieve NDCG 0.28-0.32 in production, you're doing well!"
      ],
      "metadata": {
        "id": "9xKGlVC7WO0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "good_scores = np.where(\n",
        "    true_purchases == 1,\n",
        "    rng.uniform(0.4, 0.65, true_purchases.shape),  # Relevant: moderate-high\n",
        "    rng.uniform(0.25, 0.5, true_purchases.shape)   # Irrelevant: low-moderate\n",
        ")\n",
        "\n",
        "# Create moderate errors (2-3 per user)\n",
        "for i in range(len(good_scores)):\n",
        "    wrong_indices = np.where(true_purchases[i] == 0)[0]\n",
        "    #Random item boosting so results wont be reproducible each time you run the code.\n",
        "    boost_items = rng.choice(wrong_indices, size=min(3, len(wrong_indices)), replace=False)\n",
        "    for idx in boost_items:\n",
        "        good_scores[i, idx] = rng.uniform(0.55, 0.75)\n",
        "\n",
        "df_good = pd.DataFrame(good_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"GOOD MODEL (Solid Production)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_good, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n  NDCG@5 ~0.35-0.50 is GOOD - deploy with confidence!\")\n",
        "print(f\"   Separation gap: ~0.25 (moderate signal)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE2ykY_rWSO_",
        "outputId": "8cde89cd-79e8-4b07-e974-640f42a1b51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GOOD MODEL (Solid Production)\n",
            "============================================================\n",
            "NDCG@1 = 0.0000\n",
            "NDCG@3 = 0.1152\n",
            "NDCG@5 = 0.3920\n",
            "NDCG@10 = 0.4956\n",
            "\n",
            "  NDCG@5 ~0.35-0.50 is GOOD - deploy with confidence!\n",
            "   Separation gap: ~0.25 (moderate signal)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 5 - Mediocre Model\n",
        "\n",
        "**Target NDCG: 0.15-0.25** (needs improvement)\n",
        "\n",
        "**Strategy:**\n",
        "- Heavy overlap in scores\n",
        "- Relevant items only slightly favored\n",
        "- Many wrong items ranked high\n",
        "\n",
        "**Why is 0.20 \"mediocre\"?**\n",
        "- It's only 2x better than random\n",
        "- Shows some signal but not enough\n",
        "- Needs more features, data, or better algorithm\n",
        "\n",
        "**Decision:** Improve this model before deploying to production."
      ],
      "metadata": {
        "id": "c43beqSAWWV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mediocre_scores = np.where(\n",
        "    true_purchases == 1,\n",
        "    rng.uniform(0.4, 0.70, true_purchases.shape),  # Relevant: mid-range\n",
        "    rng.uniform(0.25, 0.65, true_purchases.shape)   # Irrelevant: overlapping range\n",
        ")\n",
        "\n",
        "df_mediocre = pd.DataFrame(mediocre_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MEDIOCRE MODEL (Needs Work)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_mediocre, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n⚠️  NDCG@5 ~0.20-0.30 needs improvement before deployment\")\n",
        "print(f\"   ⚠️  If NDCG@1 > NDCG@5, model is inconsistent!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJg6KHUJWZMP",
        "outputId": "5497d6b6-4bb3-409c-825b-1e2c78154ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MEDIOCRE MODEL (Needs Work)\n",
            "============================================================\n",
            "NDCG@1 = 0.4000\n",
            "NDCG@3 = 0.2469\n",
            "NDCG@5 = 0.2868\n",
            "NDCG@10 = 0.3421\n",
            "\n",
            "⚠️  NDCG@5 ~0.20-0.30 needs improvement before deployment\n",
            "   ⚠️  If NDCG@1 > NDCG@5, model is inconsistent!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 6 - Poor Model  \n",
        "\n",
        "**Target NDCG: 0.10-0.15** (barely beats random)\n",
        "\n",
        "**Strategy:**\n",
        "- Almost no separation between relevant and irrelevant scores\n",
        "- Same score ranges for both!\n",
        "- Model hasn't learned anything useful\n",
        "\n",
        "**Why is 0.12 \"poor\"?**\n",
        "- It's only 1.2x better than random\n",
        "- Barely distinguishable from random\n",
        "- Don't waste resources deploying this\n",
        "\n",
        "**Red flag:** If your model performs like this, you need to rethink your approach."
      ],
      "metadata": {
        "id": "GF-f6S4oWdJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poor_scores = np.where(\n",
        "    true_purchases == 1,\n",
        "    rng.uniform(0.37, 0.65, true_purchases.shape),  # Relevant\n",
        "    rng.uniform(0.35, 0.65, true_purchases.shape)   # Irrelevant (SAME range!)\n",
        ")\n",
        "\n",
        "df_poor = pd.DataFrame(poor_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"POOR MODEL (Don't Deploy)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_poor, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n❌ NDCG ~0.11-0.13 is barely better than random - don't deploy!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO7jrRyCWgrR",
        "outputId": "d6d3aa5b-a996-4410-9d95-0e4f4cbbd552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "POOR MODEL (Don't Deploy)\n",
            "============================================================\n",
            "NDCG@1 = 0.0000\n",
            "NDCG@3 = 0.0603\n",
            "NDCG@5 = 0.0755\n",
            "NDCG@10 = 0.1033\n",
            "\n",
            "❌ NDCG ~0.11-0.13 is barely better than random - don't deploy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 7 - Random Baseline\n",
        "\n",
        "**Expected NDCG: ~0.10** (with 5% purchase rate)\n",
        "\n",
        "**How it works:**\n",
        "- Scores are uniformly random (0 to 1)\n",
        "- No relationship to what user will buy\n",
        "- Pure luck\n",
        "\n",
        "**Why ~0.10?**\n",
        "- With 5% relevant items, random gets ~10% of perfect score\n",
        "- This is your baseline - ANY model must beat this!\n",
        "\n",
        "**Critical:** Always measure your improvement over random:\n",
        "- Model = 0.30, Random = 0.10 → 3x improvement\n",
        "- Model = 0.12, Random = 0.10 → 1.2x improvement"
      ],
      "metadata": {
        "id": "-eji6E9cWkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_scores = rng.uniform(0, 1, true_purchases.shape)\n",
        "df_random = pd.DataFrame(random_scores, columns=products, index=df_true.index)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RANDOM BASELINE (No Model)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k in [1, 3, 5, 10]:\n",
        "    val = ndcg_score(df_true.values, df_random, k=k)\n",
        "    print(f\"NDCG@{k} = {val:.4f}\")\n",
        "\n",
        "print(\"\\n⚫ NDCG ~0.10 with 5% purchase rate - this is your baseline\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV32geTwWm-e",
        "outputId": "bbade890-3a2d-4e35-8466-2e8b22806af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "RANDOM BASELINE (No Model)\n",
            "============================================================\n",
            "NDCG@1 = 0.1000\n",
            "NDCG@3 = 0.1152\n",
            "NDCG@5 = 0.1175\n",
            "NDCG@10 = 0.1470\n",
            "\n",
            "⚫ NDCG ~0.10 with 5% purchase rate - this is your baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprehensive Comparison\n",
        "\n"
      ],
      "metadata": {
        "id": "x8PdUKp8WrdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scenarios = {\n",
        "    'Perfect': df_perfect,\n",
        "    'Inverted': df_inverted,\n",
        "    'Excellent': df_excellent,\n",
        "    'Good': df_good,\n",
        "    'Mediocre': df_mediocre,\n",
        "    'Poor': df_poor,\n",
        "    'Random': df_random\n",
        "}\n",
        "\n",
        "comparison_results = []\n",
        "\n",
        "for scenario_name, scores in scenarios.items():\n",
        "    row = {'Scenario': scenario_name}\n",
        "    for k in [1, 3, 5, 10]:\n",
        "        ndcg_val = ndcg_score(df_true.values, scores.values, k=k)\n",
        "        row[f'NDCG@{k}'] = ndcg_val\n",
        "    comparison_results.append(row)\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_results)\n",
        "df_comparison = df_comparison.set_index('Scenario')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPREHENSIVE COMPARISON - REALISTIC NDCG RANGES\")\n",
        "print(\"=\"*70)\n",
        "print(df_comparison.round(4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDp-Wm7gWudh",
        "outputId": "5cecfe0a-eb98-42b7-9bf1-e8f3ae07ebd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "COMPREHENSIVE COMPARISON - REALISTIC NDCG RANGES\n",
            "======================================================================\n",
            "           NDCG@1  NDCG@3  NDCG@5  NDCG@10\n",
            "Scenario                                  \n",
            "Perfect       1.0  1.0000  1.0000   1.0000\n",
            "Inverted      0.0  0.0000  0.0000   0.0000\n",
            "Excellent     0.6  0.5675  0.6595   0.6725\n",
            "Good          0.0  0.1152  0.3920   0.4956\n",
            "Mediocre      0.4  0.2469  0.2868   0.3421\n",
            "Poor          0.0  0.0603  0.0755   0.1033\n",
            "Random        0.1  0.1152  0.1175   0.1470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single User Deep Dive\n",
        "\n",
        "This scenario provides a deep dive into a single user’s recommendation results, showing which products they actually bought versus the top-ranked items predicted by different models.\n",
        "\n",
        "It highlights how model quality affects ranking: top models surface most of the purchased items in the top 5, while mediocre or random models fail to prioritize the user’s true interests.\n",
        "\n",
        "\n",
        "We analyze User 1 who bought: milk, eggs, bananas, apples (4 items from 50)\n",
        "\n",
        "**Look for:**\n",
        "\n",
        "1. **Excellent Model Top 5:**\n",
        "   - Contains 3-4 of the 4 items user bought\n",
        "   - Wrong items have clear business logic (related products)\n",
        "\n",
        "2. **Good Model Top 5:**\n",
        "   - Contains 2-3 of the 4 items\n",
        "   - Mix of right and wrong recommendations\n",
        "\n",
        "3. **Mediocre Model Top 5:**\n",
        "   - Contains 1-2 of the 4 items\n",
        "   - Many irrelevant recommendations\n",
        "\n",
        "4. **Random Model Top 5:**\n",
        "   - Contains 0-1 items (pure luck)\n",
        "   - Completely useless for recommendations\n",
        "\n",
        "**Key Observation:** Even \"Excellent\" isn't perfect - it misses 1 item. That's realistic!"
      ],
      "metadata": {
        "id": "OQLDzjx6W0oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_idx = 0\n",
        "user_name = f\"user_{user_idx + 1}\"\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"DETAILED ANALYSIS FOR {user_name.upper()}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Show what user actually bought\n",
        "bought_items = [products[i] for i in range(len(products)) if df_true.iloc[user_idx, i] == 1]\n",
        "print(f\"User 1 bought: {', '.join(bought_items)}\")\n",
        "print(f\"That's {len(bought_items)} items from {len(products)} products ({len(bought_items)/len(products):.1%})\\n\")\n",
        "\n",
        "# Create comparison\n",
        "user_comparison = pd.DataFrame({\n",
        "    'Product': products,\n",
        "    'Bought': df_true.iloc[user_idx].values,\n",
        "    'Excellent': df_excellent.iloc[user_idx].values,\n",
        "    'Good': df_good.iloc[user_idx].values,\n",
        "    'Mediocre': df_mediocre.iloc[user_idx].values,\n",
        "    'Random': df_random.iloc[user_idx].values\n",
        "})\n",
        "\n",
        "print(\"-\"*70)\n",
        "print(\"TOP 10 RECOMMENDATIONS - EXCELLENT MODEL\")\n",
        "print(\"-\"*70)\n",
        "top_excellent = user_comparison.sort_values('Excellent', ascending=False).head(10)\n",
        "print(top_excellent[['Product', 'Bought', 'Excellent']].to_string(index=False))\n",
        "print(f\"\\n✓ Top 5 contains {top_excellent.head(5)['Bought'].sum():.0f}/4 items user bought\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"TOP 10 RECOMMENDATIONS - GOOD MODEL\")\n",
        "print(\"-\"*70)\n",
        "top_good = user_comparison.sort_values('Good', ascending=False).head(10)\n",
        "print(top_good[['Product', 'Bought', 'Good']].to_string(index=False))\n",
        "print(f\"\\n✓ Top 5 contains {top_good.head(5)['Bought'].sum():.0f}/4 items user bought\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"TOP 10 RECOMMENDATIONS - MEDIOCRE MODEL\")\n",
        "print(\"-\"*70)\n",
        "top_mediocre = user_comparison.sort_values('Mediocre', ascending=False).head(10)\n",
        "print(top_mediocre[['Product', 'Bought', 'Mediocre']].to_string(index=False))\n",
        "print(f\"\\n⚠️  Top 5 contains {top_mediocre.head(5)['Bought'].sum():.0f}/4 items user bought\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"TOP 10 RECOMMENDATIONS - RANDOM MODEL\")\n",
        "print(\"-\"*70)\n",
        "top_random = user_comparison.sort_values('Random', ascending=False).head(10)\n",
        "print(top_random[['Product', 'Bought', 'Random']].to_string(index=False))\n",
        "print(f\"\\n❌ Top 5 contains {top_random.head(5)['Bought'].sum():.0f}/4 items user bought\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugGSDRS8W5cS",
        "outputId": "cb3b0dfd-0b79-4854-a2ea-41de63c236a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DETAILED ANALYSIS FOR USER_1\n",
            "======================================================================\n",
            "\n",
            "User 1 bought: milk, eggs, bananas, apples\n",
            "That's 4 items from 50 products (8.0%)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOP 10 RECOMMENDATIONS - EXCELLENT MODEL\n",
            "----------------------------------------------------------------------\n",
            "     Product  Bought  Excellent\n",
            "        milk       1   0.857859\n",
            "    tomatoes       0   0.813153\n",
            "     bananas       1   0.802444\n",
            "      butter       0   0.794712\n",
            "        eggs       1   0.734476\n",
            "      turkey       0   0.690133\n",
            "        tuna       0   0.688501\n",
            "      bagels       0   0.685236\n",
            "        beef       0   0.682664\n",
            "frozen_pizza       0   0.680430\n",
            "\n",
            "✓ Top 5 contains 3/4 items user bought\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOP 10 RECOMMENDATIONS - GOOD MODEL\n",
            "----------------------------------------------------------------------\n",
            "      Product  Bought     Good\n",
            "   sour_cream       0 0.733065\n",
            "        flour       0 0.653716\n",
            "    ice_cream       0 0.614324\n",
            "         milk       1 0.569005\n",
            "         pork       0 0.491286\n",
            "         eggs       1 0.482869\n",
            "        bread       0 0.472564\n",
            "     potatoes       0 0.471291\n",
            "      bananas       1 0.468209\n",
            "water_bottles       0 0.464795\n",
            "\n",
            "✓ Top 5 contains 1/4 items user bought\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOP 10 RECOMMENDATIONS - MEDIOCRE MODEL\n",
            "----------------------------------------------------------------------\n",
            " Product  Bought  Mediocre\n",
            "  apples       1  0.697187\n",
            "    soda       0  0.641692\n",
            "    pork       0  0.626853\n",
            "   beans       0  0.606951\n",
            "    milk       1  0.606801\n",
            " lettuce       0  0.606681\n",
            "potatoes       0  0.605084\n",
            "  salmon       0  0.604390\n",
            "  yogurt       0  0.589834\n",
            "  bagels       0  0.587907\n",
            "\n",
            "⚠️  Top 5 contains 2/4 items user bought\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "TOP 10 RECOMMENDATIONS - RANDOM MODEL\n",
            "----------------------------------------------------------------------\n",
            "    Product  Bought   Random\n",
            "     apples       1 0.997543\n",
            "       beef       0 0.985046\n",
            "  cucumbers       0 0.983822\n",
            "apple_juice       0 0.962380\n",
            "    bananas       1 0.902608\n",
            "       eggs       1 0.865829\n",
            "      chips       0 0.843254\n",
            "   tomatoes       0 0.773399\n",
            "       tuna       0 0.754221\n",
            "    chicken       0 0.753633\n",
            "\n",
            "❌ Top 5 contains 2/4 items user bought\n"
          ]
        }
      ]
    }
  ]
}